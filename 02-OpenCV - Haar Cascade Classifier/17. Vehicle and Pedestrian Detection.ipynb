{"cells":[{"cell_type":"markdown","metadata":{"id":"34s_qOEpJVA3"},"source":["![](https://raw.githubusercontent.com/jbottala02/CSC_126-2025/refs/heads/main/CSC-126%20GRAPHICS%20AND%20VISUAL%20COMPUTING.png)\n","\n","# **Vehicle and Pedestrian Detection**\n","\n","#### **In this lesson we'll learn:**\n","1. Use a Haarcascade classier to detect Pedestrians\n","2. Use our Haarcascade classifiers on videos\n","3. Use a Haarcascade classier to detect Vehicles or cars\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBUwjhke4-pv"},"outputs":[],"source":["# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Define our imshow function\n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our videos and Haarcascade Classifiers\n","!gdown --id 1aKIopVtlHmx3rKIND9TSqEVj5-f4DKSk\n","!gdown --id 15EdAwdCY8JD_6PwmXShXagbi6vsBB2ck\n","\n","!unzip -qq haarcascades.zip\n","!unzip -qq videos.zip"]},{"cell_type":"markdown","metadata":{"id":"QYCV0ONbIFf3"},"source":["#### **Testing on a Single Frame from our Video**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRUCYimVHxFY"},"outputs":[],"source":["# Create our video capturing object\n","cap = cv2.VideoCapture('walking.mp4')\n","\n","# Load our body classifier\n","body_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_fullbody.xml')\n","\n","# Read first frame\n","ret, frame = cap.read()\n","\n","# Ret is True if successfully read\n","if ret:\n","\n","  #Grayscale our image for faster processing\n","  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","  # Pass frame to our body classifier\n","  bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n","\n","  # Extract bounding boxes for any bodies identified\n","  for (x,y,w,h) in bodies:\n","      cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n","\n","# Release our video capture\n","cap.release()\n","imshow(\"Pedestrian Detector\", frame)"]},{"cell_type":"markdown","metadata":{"id":"ixAIvrHlIJmq"},"source":["#### **Testing on our 15 second clip**\n","\n","**NOTE**: Takes around 1 minute to run.\n","\n","We use cv2.VideoWriter to save the output as an AVI file.\n","\n","```cv2.VideoWriter(video_output.avi, cv2.VideoWriter_fourcc('M','J','P','G'), FPS, (width, height))```\n","\n","Formats can be:\n","- 'M','J','P','G' or MJPG\n","- MP4V\n","- X264\n","- avc1\n","- XVID\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMQyWFv-5PX2"},"outputs":[],"source":["# Create our video capturing object\n","cap = cv2.VideoCapture('walking.mp4')\n","\n","# Get the height and width of the frame (required to be an interfer)\n","w = int(cap.get(3))\n","h = int(cap.get(4))\n","\n","# Define the codec and create VideoWriter object.The output is stored in 'walking_output.avi' file.\n","out = cv2.VideoWriter('walking_output.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (w, h))\n","\n","body_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_fullbody.xml')\n","\n","# Loop once video is successfully loaded\n","while(True):\n","\n","  ret, frame = cap.read()\n","  if ret:\n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Pass frame to our body classifier\n","    bodies = body_detector.detectMultiScale(gray, 1.2, 3)\n","\n","    # Extract bounding boxes for any bodies identified\n","    for (x,y,w,h) in bodies:\n","        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n","\n","    # Write the frame into the file 'output.avi'\n","    out.write(frame)\n","  else:\n","      break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"markdown","metadata":{"id":"DibN9NjFBbaO"},"source":["## **Play Video within Colab**\n","Steps\n","1. Convert the AVI file to MP4 using FFMPEG\n","2. Load the HTML plugins in IPython\n","3. Display our HTML video player"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgU28hq2BPYp"},"outputs":[],"source":["!ffmpeg -i /content/walking_output.avi walking_output.mp4 -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpZYa-srBET0"},"outputs":[],"source":["from IPython.display import HTML\n","from base64 import b64encode\n","\n","mp4 = open('walking_output.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0i27M_72BLkY"},"outputs":[],"source":["HTML(\"\"\"\n","<video controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"cell_type":"markdown","metadata":{"id":"3fquhUYvKKof"},"source":["#### **Vehicle Detection on Single Image**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgXAdsfGKQ7A"},"outputs":[],"source":["# Create our video capturing object\n","cap = cv2.VideoCapture('cars.mp4')\n","\n","# Load our vehicle classifier\n","vehicle_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_car.xml')\n","\n","# Read first frame\n","ret, frame = cap.read()\n","\n","# Ret is True if successfully read\n","if ret:\n","\n","  #Grayscale our image for faster processing\n","  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","  # Pass frame to our body classifier\n","  vehicles = vehicle_detector.detectMultiScale(gray, 1.4, 2)\n","\n","  # Extract bounding boxes for any bodies identified\n","  for (x,y,w,h) in vehicles:\n","      cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n","\n","# Release our video capture\n","cap.release()\n","imshow(\"Vehicle Detector\", frame)"]},{"cell_type":"markdown","metadata":{"id":"Zwce5GRTK4Km"},"source":["#### **Testing on our 15 second clip**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DCehATFK3Od"},"outputs":[],"source":["# Create our video capturing object\n","cap = cv2.VideoCapture('cars.mp4')\n","\n","# Get the height and width of the frame (required to be an interfer)\n","w = int(cap.get(3))\n","h = int(cap.get(4))\n","\n","# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n","out = cv2.VideoWriter('cars_output.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (w, h))\n","\n","vehicle_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_car.xml')\n","\n","# Loop once video is successfully loaded\n","while(True):\n","\n","  ret, frame = cap.read()\n","  if ret:\n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Pass frame to our body classifier\n","    vehicles = vehicle_detector.detectMultiScale(gray, 1.2, 3)\n","\n","    # Extract bounding boxes for any bodies identified\n","    for (x,y,w,h) in vehicles:\n","        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n","\n","    # Write the frame into the file 'output.avi'\n","    out.write(frame)\n","  else:\n","      break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vT3CsWLSirHf"},"outputs":[],"source":["!ffmpeg -i /content/cars_output.avi cars_output.mp4 -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgopCDZCB1Fq"},"outputs":[],"source":["from IPython.display import HTML\n","from base64 import b64encode\n","\n","mp4 = open('cars_output.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OzJ-cjY_B6Rb"},"outputs":[],"source":["HTML(\"\"\"\n","<video controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zV8B6eKXLYbB"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}