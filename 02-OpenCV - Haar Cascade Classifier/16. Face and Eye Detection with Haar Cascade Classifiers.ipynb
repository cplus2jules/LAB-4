{"cells":[{"cell_type":"markdown","metadata":{"id":"RVy1nTr0MMMA"},"source":["![](https://raw.githubusercontent.com/jbottala02/CSC_126-2025/refs/heads/main/CSC-126%20GRAPHICS%20AND%20VISUAL%20COMPUTING.png)\n","# **Face and Eye Detection with Haar Cascade Classifiers**\n","\n","#### **In this lesson we'll learn:**\n","1. To use a Haarcascade Classifer to detect faces\n","2. To use a Haarcascade Classifer to detect eyes\n","3. To use a Haarcascade Classifer to detect faces and eyes from your webcam in Colab\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSMmBq2zLyEn"},"outputs":[],"source":["# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Define our imshow function\n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our images and Haarcascade Classifiers\n","!gdown --id 1qxuPaG5nqZF17Q2dZ6jmX516736yYoNv\n","!gdown --id 15EdAwdCY8JD_6PwmXShXagbi6vsBB2ck\n","\n","!unzip -qq images.zip\n","!unzip -qq haarcascades.zip"]},{"cell_type":"markdown","metadata":{"id":"eZCl1VMKNILR"},"source":["## **Simple Face Detection using Haarcascade Classifiers**\n","\n","### **Firstly, What is Object Detection?**\n","\n","![](https://raw.githubusercontent.com/jbottala02/CSC_126-2025/refs/heads/main/1_zlWrCk1hBBFRXa5t84lmHQ.png)\n","\n","**Object Detection** is the ability to detect and classify individual objects in an image and draw a bounding box over the object's area."]},{"cell_type":"markdown","metadata":{"id":"pzRutW5o8SNQ"},"source":["## **HAAR Cascade Classifiers**\n","\n","Developed by Viola and Jones in 2001.\n","\n","An object detection method that uses a series of classifiers (cascade) to identify objects in an image. They are trained to identify one type of object, however, we can use several of them in parallel e.g. detecting eyes and faces together. HAAR Classifiers are trained using lots of positive images (i.e. images with the object present) and negative images (i.e. images without the object present).\n","![](https://raw.githubusercontent.com/jbottala02/CSC_126-2025/refs/heads/main/haar.png)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnJEWS6BMfWC"},"outputs":[],"source":["# We point OpenCV's CascadeClassifier function to where our\n","# classifier (XML file format) is stored\n","face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n","\n","# Load our image then convert it to grayscale\n","image = cv2.imread('images/Trump.jpg')\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# Our classifier returns the ROI of the detected face as a tuple\n","# It stores the top left coordinate and the bottom right coordiantes\n","faces = face_classifier.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No faces found\")\n","\n","# We iterate through our faces array and draw a rectangle\n","# over each face in faces\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n","\n","imshow('Face Detection', image)"]},{"cell_type":"markdown","metadata":{"id":"v6tKH-9LNNdY"},"source":["## **Simple Eye & Face Detection using Haarcascade Classifiers**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gaYe7eC-NFTq"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n","\n","img = cv2.imread('images/Trump.jpg')\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No Face Found\")\n","\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n","    roi_gray = gray[y:y+h, x:x+w]\n","    roi_color = img[y:y+h, x:x+w]\n","    eyes = eye_classifier.detectMultiScale(roi_gray, 1.2, 3)\n","    for (ex,ey,ew,eh) in eyes:\n","        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n","\n","imshow('Eye & Face Detection',img)"]},{"cell_type":"markdown","metadata":{"id":"UvAlz3z0Nt6y"},"source":["## **Using Colab's Code Snippets let's access the webcam for an input**\n","\n","Note: Requires your computer to have a webcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4kjOYxFNsFq"},"outputs":[],"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lMY00RNNsFq"},"outputs":[],"source":["from IPython.display import Image\n","try:\n","  filename = take_photo()\n","  print('Saved to {}'.format(filename))\n","\n","  # Show the image which was just taken.\n","  display(Image(filename))\n","except Exception as err:\n","  # Errors will be thrown if the user does not have a webcam or if they do not\n","  # grant the page permission to access it.\n","  print(str(err))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqTdZf-zN496"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n","\n","img = cv2.imread('photo.jpg')\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No Face Found\")\n","\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n","    roi_gray = gray[y:y+h, x:x+w]\n","    roi_color = img[y:y+h, x:x+w]\n","    eyes = eye_classifier.detectMultiScale(roi_gray)\n","    for (ex,ey,ew,eh) in eyes:\n","        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n","\n","imshow('Eye & Face Detection',img)"]},{"cell_type":"markdown","metadata":{"id":"gv3mnMy0OQhw"},"source":["### **Bonus Code - Use your webcam to do live face and eye detection**\n","\n","This only works on a local machine, will not work in Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-RcgH28ON9B"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n","\n","def face_detector(img, size=0.5):\n","    # Convert image to grayscale\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","    if faces is ():\n","        return img\n","\n","    for (x,y,w,h) in faces:\n","        x = x - 50\n","        w = w + 50\n","        y = y - 50\n","        h = h + 50\n","        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n","        roi_gray = gray[y:y+h, x:x+w]\n","        roi_color = img[y:y+h, x:x+w]\n","        eyes = eye_classifier.detectMultiScale(roi_gray)\n","\n","        for (ex,ey,ew,eh) in eyes:\n","            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n","\n","    roi_color = cv2.flip(roi_color,1)\n","    return roi_color\n","\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","\n","    ret, frame = cap.read()\n","    cv2.imshow('Our Face Extractor', face_detector(frame))\n","    if cv2.waitKey(1) == 13: #13 is the Enter Key\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}